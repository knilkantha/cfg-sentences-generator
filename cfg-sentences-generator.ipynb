{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables, names, paths\n",
    "\n",
    "#number of sentences to generate\n",
    "num_sentences = 10000\n",
    "\n",
    "#max number of words in a sentence\n",
    "\n",
    "max_depth = 10\n",
    "\n",
    "#grammar file name\n",
    "grammar_file = 'grammar.gr'\n",
    "sentences = set()\n",
    "#file to save sentences\n",
    "save_file_name = 'generated_sentence.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Parse Grammar from Grammar File\n",
    "\n",
    "def parse_grammar_file(grammar_file, delimiter='\\t'):\n",
    "    \n",
    "    rules = {}\n",
    "\n",
    "    with open(grammar_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            #skip empty lines and comments\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            #Removes comments after code\n",
    "            line = line.split(\"#\")[0].strip()\n",
    "\n",
    "            grammar_line = line.split(delimiter) #gives in format ['1', 'ROOT', 'S .'] \n",
    "\n",
    "            non_terminal = grammar_line[1] #gives in parts ROOT\n",
    "            other_parts = grammar_line[2] #gives in parts S .\n",
    "\n",
    "            # use non_terminals as dictionary keys\n",
    "            if non_terminal in rules:\n",
    "                rules[non_terminal].append(other_parts)\n",
    "            else:\n",
    "                rules[non_terminal] = [other_parts]\n",
    "\n",
    "    return rules\n",
    "\n",
    "# parse_grammar_file('grammar.gr', '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sentences from grammar\n",
    "def generate_sentence(grammar, symbol, max_depth=10, current_depth=0):\n",
    "    if current_depth >= max_depth:  # Limit the recursion depth\n",
    "        return []\n",
    "\n",
    "    if symbol not in grammar:\n",
    "        return [symbol]\n",
    "    else:\n",
    "        production = random.choice(grammar[symbol])\n",
    "        return [token for prod_symbol in production.split() \n",
    "                for token in generate_sentence(grammar, prod_symbol, max_depth, current_depth + 1)]\n",
    "\n",
    "#Gerateing sentences {count} number of times and storing them in a set to make them unique\n",
    "# and finally converting to list\n",
    "def generate_sentences(grammar, symbol, count, max_depth):\n",
    "    sentences = set()\n",
    "    while len(sentences) < count:\n",
    "        sentence = generate_sentence(grammar, symbol, max_depth)\n",
    "        if sentence:  # Avoid adding empty sentences\n",
    "            sentences.add(' '.join(sentence))\n",
    "    return list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse grammar file\n",
    "grammar = parse_grammar_file('grammar.gr', '\\t')\n",
    "\n",
    "#Generate Sentence\n",
    "sentences_list = generate_sentences(grammar, 'ROOT', 10000, max_depth)\n",
    "\n",
    "#save sentences to file\n",
    "with open(save_file_name, \"w\") as file:\n",
    "    file.writelines(\"\\n\".join(sentences_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
