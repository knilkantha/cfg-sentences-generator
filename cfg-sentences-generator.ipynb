{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables, names, paths\n",
    "\n",
    "#number of sentences to generate\n",
    "num_sentences = 10000\n",
    "\n",
    "#max number of words in a sentence\n",
    "\n",
    "max_depth = 10\n",
    "\n",
    "#grammar file name\n",
    "grammar_file = 'grammar.gr'\n",
    "sentences = set()\n",
    "#file to save sentences\n",
    "save_file_name = 'generated_sentence.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Parse Grammar from Grammar File\n",
    "\n",
    "def parse_grammar_file(grammar_file, delimiter='\\t'):\n",
    "    \n",
    "    rules = {} #dictionary to store grammar rules\n",
    "\n",
    "    with open(grammar_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            #skip empty lines and comments\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            #Removes comments after code\n",
    "            line = line.split(\"#\")[0].strip()\n",
    "\n",
    "            grammar_line = line.split(delimiter) #gives in format ['1', 'ROOT', 'S .'] \n",
    "\n",
    "            non_terminal = grammar_line[1] #gives in parts ROOT\n",
    "            other_parts = grammar_line[2] #gives in parts S .\n",
    "\n",
    "            # use non_terminals as dictionary keys\n",
    "            ''' Initially rules is empty, so it will go to else part and add the non_terminal as key and other_parts as value in the dictionary. \n",
    "            And, when it will find the same non_terminal again, it will append the other_parts to the value of the non_terminal key. \n",
    "\n",
    "            Here, rules is Dictionary data so, its content will in key value pair format.\n",
    "             - key:value\n",
    "             - key - non_terminal, single value \"string\", for eg. ROOT\n",
    "             - value - other_parts, list of values \"list items\", for eg. ['S .', 'S !', 'is it true that S ?']\n",
    "             - 'ROOT': ['S .', 'S !', 'is it true that S ?']\n",
    "            '''\n",
    "            if non_terminal in rules:\n",
    "                rules[non_terminal].append(other_parts)\n",
    "            else:\n",
    "                rules[non_terminal] = [other_parts]\n",
    "\n",
    "    return rules\n",
    "\n",
    "# parse_grammar_file('grammar.gr', '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Function to generate sentences from grammar it may return incomplete sentence\n",
    "\n",
    "def generate_sentence(grammar, symbol, max_depth=10, current_depth=0):\n",
    "    if current_depth >= max_depth:  # Limit the recursion depth\n",
    "        return [] # return empty list when sentence generation reaches max_depth\n",
    "\n",
    "    if symbol not in grammar:\n",
    "        return [symbol]\n",
    "    else:\n",
    "        production = random.choice(grammar[symbol])\n",
    "        return [token for prod_symbol in production.split() \n",
    "                for token in generate_sentence(grammar, prod_symbol, max_depth, current_depth + 1)]\n",
    "\n",
    "#Gerateing sentences {count} number of times and storing them in a set to make them unique\n",
    "# and finally converting to list\n",
    "def generate_sentences(grammar, symbol, count, max_depth):\n",
    "    sentences = set()\n",
    "\n",
    "    #Checking the length of the set, as set does not allow duplicates and we are not storing duplicates \n",
    "    #so it gives exact number of sentences and we can iteratea until we get total number of sentences \n",
    "    #even when we are getting duplicates and empty due to recursion depth stoping the sentence generation\n",
    "    while len(sentences) < count: \n",
    "        sentence = generate_sentence(grammar, symbol, max_depth)\n",
    "        if sentence:  # Avoid adding empty sentences\n",
    "            sentences.add(' '.join(sentence))\n",
    "    return list(sentences)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sentences from grammar\n",
    "\n",
    "def generate_sentence(grammar, symbol, max_depth=10, current_depth=0):\n",
    "    if current_depth >= max_depth:  # Limit the recursion depth\n",
    "        return None  # return None when sentence generation reaches max_depth\n",
    "\n",
    "    if symbol not in grammar:\n",
    "        return [symbol]\n",
    "    else:\n",
    "        production = random.choice(grammar[symbol])\n",
    "        sentence = []\n",
    "        for prod_symbol in production.split():\n",
    "            generated = generate_sentence(grammar, prod_symbol, max_depth, current_depth + 1)\n",
    "            if generated is None:  # If a part of the sentence could not be generated, return None\n",
    "                return None\n",
    "            sentence.extend(generated)\n",
    "        return sentence\n",
    "\n",
    "#Gerateing sentences {count} number of times and storing them in a set to make them unique\n",
    "# and finally converting to list\n",
    "def generate_sentences(grammar, symbol, count, max_depth):\n",
    "    sentences = set()\n",
    "\n",
    "    #Checking the length of the set, as set does not allow duplicates and we are not storing duplicates \n",
    "    #so it gives exact number of sentences and we can iterate until we get total number of sentences \n",
    "    #even when we are getting duplicates and None due to recursion depth stoping the sentence generation\n",
    "    while len(sentences) < count: \n",
    "        sentence = generate_sentence(grammar, symbol, max_depth)\n",
    "        if sentence is not None:  # Ignore sentences that are None\n",
    "            sentences.add(' '.join(sentence))\n",
    "    return list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse grammar file\n",
    "grammar = parse_grammar_file('grammar.gr', '\\t') #returns dictionary\n",
    "\n",
    "#Generate Sentence\n",
    "sentences_list = generate_sentences(grammar, 'ROOT', 10000, max_depth)\n",
    "\n",
    "#save sentences to file\n",
    "with open(save_file_name, \"w\") as file:\n",
    "    file.writelines(\"\\n\".join(sentences_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
